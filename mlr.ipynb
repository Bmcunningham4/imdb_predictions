{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression Analysis\n",
    "Imports and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import  mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "#? Filter Methods: Pearson Correlation between features, \n",
    "X_num = ratings_df[['IMDb Rating', 'Runtime (mins)', 'Year', 'Num Votes', 'Day_Rated']]\n",
    "y = ratings_df[\"Your Rating\"]\n",
    "\n",
    "corr_matrix = X_num.corr(method='pearson')\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "heatmap = sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r')\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.title('Pearson Correlation Matrix for Numerical Features')\n",
    "plt.show()\n",
    "print(\"Since there is no correlation between features, greater than 0.7 or less than -0.7. \\nNo features will be removed\")\n",
    "\n",
    "#? Correlation between featue and target - Especially important since using linear relationship here!\n",
    "X_y = X_num.copy()\n",
    "X_y[\"Your Rating\"] = y\n",
    "\n",
    "corr_matrix = X_y.corr()\n",
    "corr_target = corr_matrix[['Your Rating']].drop(labels=['Your Rating'])\n",
    "sorted_corr = corr_target.abs().sort_values(by='Your Rating', ascending=False)\n",
    "sns.heatmap(sorted_corr, annot=True, fmt='.3', cmap='RdBu_r')\n",
    "plt.show()\n",
    "print(\"Runtime, Num votes and Day Rated all seem to show very low correlation to my rating. \\nSo I will try 1 model with thesee values removed and 1 keeping them\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training - For 2 different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratings_df[['IMDb Rating', 'Runtime (mins)', 'Year', 'Num Votes', 'Day_Rated']]\n",
    "X_2 = ratings_df[[\"IMDb Rating\", \"Num Votes\"]]\n",
    "y = ratings_df['Your Rating']\n",
    "\n",
    "#? Model 1 & 2 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_2, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Model 1) \\nMean Absolute Error: {round(mae, 3)}')\n",
    "train_score = model.score(X_train_scaled, y_train)\n",
    "print(f'Training R-squared: {round(train_score, 3)}')\n",
    "test_score = model.score(X_test_scaled, y_test)\n",
    "print(f'Test R-squared: {round(test_score, 3)}', '\\n')\n",
    "\n",
    "print('Model 2) \\nMean Absolute Error: 0.927 ')\n",
    "print('Test R-squared: 0.298')\n",
    "print('Training R-squared: 0.263', '\\n')\n",
    "print(\"Despite model 2 demonstrating better point-wise accuracy with lower MAE, \\nI would chose model 1 due to it's superior overall explanatory power reflected in higher R-sqaured scores \")\n",
    "# print(model.coef_)\n",
    "# print(model.intercept_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Watchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(watchlist_df.head())\n",
    "\n",
    "#...\n",
    "watchlist_scaled = scaler.transform(watchlist_df)\n",
    "predictions = model.predict(watchlist_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of predicted vs actual rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, alpha=0.4)\n",
    "plt.xlabel(\"Ratings: /10\")\n",
    "plt.ylabel(\"Predicted Ratings: /10\")\n",
    "plt.title(\"Actual Ratings vs Predicted Ratings\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the relationships between features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_loop(df, var_list):\n",
    "    for variable in var_list:\n",
    "        plt.scatter(df[[variable]], df[\"Your Rating\"], alpha = 0.4)\n",
    "        plt.xlabel(variable)\n",
    "        plt.ylabel(\"My Rating\")\n",
    "        plt.show()\n",
    "    return \"\"\n",
    "\n",
    "print(scatter_loop(ratings_df, X)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
